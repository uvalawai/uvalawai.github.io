# Schedule

### Week 1 (29 August 2025)

**Pre-Course Survey**

_cs4501 students only_: Submit this pre-course survey before **5pm** on **Thursday, 28 August**:   
[cs4501: Pre-Course Survey](https://forms.gle/ApXvZV5LorAX2SD46) (Google Form)

**Readings:** (to be read before class)
- Frank H. Easterbrook, [_Cyberspace and the Law of the Horse_](/readings/easterbrook.pdf), 1996 University of Chicago Legal Forum 207 (1996). [[PDF](/readings/easterbrook.pdf)]
- Ted Chiang, [_ChatGPT is a Blurry JPEG of the Web_](/readings/chiang.pdf), The New Yorker, 9 February 2023. [[PDF](/readings/chiang.pdf)] [[Original Site](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web)]

### Week 2

**Readings:** (to be read and thought about before classs on Friday 5 September)

- Mark Riedl, [_The Intuition Behind How Large Language Models Work_, Part I](https://mark-riedl.medium.com/the-intuition-behind-how-large-language-models-work-166cf2fb278a), Medium (Aug. 6, 2025). 
- Mark Riedl, [_The Intuition Behind How Large Language Models Work_, Part II](https://mark-riedl.medium.com/the-intuition-behind-how-large-language-models-work-part-ii-8c6a127a4a99), Medium (Aug. 13, 2025) 
- William A. Ryan, et al., [_Practical Lessons from the Attorney AI Missteps in Mata v. Avianca_](https://www.acc.com/resource-library/practical-lessons-attorney-ai-missteps-mata-v-avianca), Association of Corporate Counsel (Aug. 8, 2023). 
- [_Introduction to Law and Legal Systems_](https://saylordotorg.github.io/text_introduction-to-the-law-of-property-estate-planning-and-insurance/s04-introduction-to-law-and-legal-.html), Chapter 1 from Don Mayer et al., Introduction to the Law of Property, Estate Planning and Insurance (2012) 

The Law students are also reading the first three readings, but not the Introduction to Law and Legal Systems chapter, which covers things they are expected to already know well from having at least a year of Law school. Please think about any questions you have from that and ask them in class (or email us before class) on Friday.

**Homework**

- Submit the Homework 1: Using LLMs assignment in canvas by 9pm on Wednesday:
[https://canvas.its.virginia.edu/courses/147155/assignments/757555](https://canvas.its.virginia.edu/courses/147155/assignments/757555)


- If you joined the class late and missed the message about the pre-course survey, please make sure to submit this soon:
[https://forms.gle/ApXvZV5LorAX2SD46](https://forms.gle/ApXvZV5LorAX2SD46)

Link to notebooks from class:
- [Exploring Tokens](https://colab.research.google.com/drive/1GGgUX2dfhB0pHacsZBuKxWMfysG1_PTE)
- [Exploring Embeddings](https://colab.research.google.com/drive/1QJ9SOQGF27082vJntioBSC2SLnBd-FGx?usp=sharing)

Note to run these yourself, you will need to get a token from https://huggingface.co/.

### Week 3

**Readings:**

- Solon Barocas, Moritz Hardt & Arvind Narayanan, Chapter 3: Classification from Fairness and Machine Learning (2023). [Chapter link](https://fairmlbook.org/classification.html) or [PDF](https://fairmlbook.org/pdf/classification.pdf)
- Solon Barocas & Andrew D. Selbst, Big Data's Disparate Impact, 104 California Law Review 671 (2016), https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2477899. [Direct PDF link](/readings/barocas.pdf)

**Homework**

- Submit [Homework 2: Document Bot](https://canvas.its.virginia.edu/courses/147155/assignments/762232) in canvas before 9pm on Wednesday, 10 September. Note that this requires reading the Barocas & Selbst paper first.

### Week 4

**Project 1:** [Notebook Link](https://colab.research.google.com/drive/18ww7xI7-OeUFa3Bq8P10Z0Ui1cw_uUax)

**Readings:**
- Solon Barocas, Moritz Hardt & Arvind Narayanan, Chapter 5: Causality from Fairness and Machine Learning (2023). [Chapter link](https://fairmlbook.org/causal.html) or [PDF](https://fairmlbook.org/pdf/causal.pdf)
- Nripsuta Saxena and Karen Huang and Evan DeFilippis and Goran Radanovic and David Parkes and Yang Liu. [_How Do Fairness Definitions Fare? Examining Public Attitudes Towards Algorithmic Definitions of Fairness_](https://arxiv.org/pdf/1811.03654). AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES), 2019. Conference Link: [PDF](https://www.aies-conference.com/2019/wp-content/papers/main/AIES-19_paper_229.pdf).
- Thomas B. Nachbar, [Algorithmic Fairness, Algorithmic Discrimination](/readings/nachbar-fairness.pdf). 48 Florida State University Law Review 509 (2021). 

There is no assignment to submit this week, but we are expecting teams to get to the part of the Project 1 notebook marked as "Target for Week 1". Your completed Project 1 notebook will be due on Wednesday, 24 September.

### Week 5

**Project 1:** Project 1 is due on Wednesday (Sept 24) at 9pm. Each team should submit their Project 1 using the [Group Project 1](https://canvas.its.virginia.edu/courses/147155/assignments/766672) assignment in Canvas. Only one team member submits your PDF for the full team.

**Slides:** The slides for today's class (and all previous classes) are in the ["Files/Class Slides" directory in Canvas](https://canvas.its.virginia.edu/courses/147155/files). 

**Readings:** 

- P. Jonathan Phillips, et al., _Four Principles of Explainable Artificial Intelligence_, NIST Interagency/Internal Report (NISTIR) 8312 (2021): [https://doi.org/10.6028/NIST.IR.8312](https://doi.org/10.6028/NIST.IR.8312)

- Christoph Molnars, _Interpretable Machine Learning: A Guide for Making Black Box Models Explainable_, Chapter 17: _Shapley Values_. [https://christophm.github.io/interpretable-ml-book/shapley.html](https://christophm.github.io/interpretable-ml-book/shapley.html) (Law students can skip the &ldquo;Shapley value theory&rdquo; section, but we encourage CS students to read it)
- Aidan Cooper, _Explaining Machine Learning Models: A Non-Technical Guide to Interpreting SHAP Analyses_: [https://www.aidancooper.co.uk/a-non-technical-guide-to-interpreting-shap-analyses/](https://www.aidancooper.co.uk/a-non-technical-guide-to-interpreting-shap-analyses/)

### Week 6: Copyright

[**Project 2 Notebook**](https://colab.research.google.com/drive/1hmgTI2rNYEdntNzNXd0kmIbyxEpRZiRD?usp=sharing) Project 2 is due **Wednesday, 9:00pm**.

**Readings:**

- A. Feder Cooper, Aaron Gokaslan, Ahmed Ahmed, Amy B. Cyphert, Christopher De Sa, Mark A. Lemley, Daniel E. Ho, Percy Liang. _Extracting memorized pieces of (copyrighted) books from open-weight language models_.  [https://arxiv.org/abs/2505.12546](https://arxiv.org/abs/2505.12546)  (Don’t be scared by the 171 pages! The part to read is only the first 17 pages, the rest are appendices.)

- Regina Sam Penti, Matthew J. Rizzolo & Yam Schaal. _Anthropic’s Landmark Copyright Settlement: Implications for AI Developers and Enterprise Users_, Ropes & Gray (Sept. 8, 2025). [https://www.ropesgray.com/en/insights/alerts/2025/09/anthropics-landmark-copyright-settlement-implications-for-ai-developers-and-enterprise-users](https://www.ropesgray.com/en/insights/alerts/2025/09/anthropics-landmark-copyright-settlement-implications-for-ai-developers-and-enterprise-users) 
 
- U.S. Copyright Office. _Copyright and Artificial Intelligence Part 3: Generative AI Training_ (prepublication version May 2025). [https://www.copyright.gov/ai/Copyright-and-Artificial-Intelligence-Part-3-Generative-AI-Training-Report-Pre-Publication-Version.pdf](https://www.copyright.gov/ai/Copyright-and-Artificial-Intelligence-Part-3-Generative-AI-Training-Report-Pre-Publication-Version.pdf)  You are only expected to read pages 1-31, on the basic technology (which will be a refresher) and on infringement. We will talk about fair use, but we will be focusing on the infringement inquiry.

- John M. Griem, Jr. and Judith Wallace. )Managing the Risk of Using AI-Generated Content in a World of Copyright Uncertainty: Are AI Content Generators and AI Generated Expressions “Derivatives” of Copyrighted Works?_. Carter Ledyard (Aug, 28, 2023). [https://www.clm.com/managing-the-risk-of-using-ai-generated-content-in-a-world-of-copyright-uncertainly-are-ai-content-generators-and-ai-generated-expressions-derivatives-of-copyrighted-works/](https://www.clm.com/managing-the-risk-of-using-ai-generated-content-in-a-world-of-copyright-uncertainly-are-ai-content-generators-and-ai-generated-expressions-derivatives-of-copyrighted-works/)
